{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKc7XHK8cCUf"
      },
      "source": [
        "# Implementation of the Transformer architecture\n",
        "\n",
        "### This is the notebook used to train and test the SPARQL NMT Transformer model for the Knowledge Base-aware SPARQL Query Translation from Natural Language article\n",
        "\n",
        "\n",
        "Here are some interesting references that helped us in our implementation:\n",
        "- https://github.com/bentrevett/pytorch-seq2seq\n",
        "- https://huggingface.co/spaces/gradio/HuBERT/blob/main/fairseq/models/transformer.py\n",
        "- https://github.com/cestwc/pointer-transformer-model-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TACu-7wh4pQ"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Please note that using [wandb](https://wandb.ai/site) is not required, but suggested as it provides a great way to track model perfomances during training. Install the package and set the const USE_WANDB to true if you wish to use it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnUaflE-4Rcm",
        "outputId": "3824e3ca-7545-4088-a176-8c32996a119e"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install SPARQLWrapper\n",
        "!pip install torchtext==0.11.0\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IHvt39H4xi-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "from torchtext.legacy.data.dataset import TabularDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from transformers import BertModel, AutoModel\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "\n",
        "from transformers import EncoderDecoderModel, AutoTokenizer, BertTokenizer\n",
        "\n",
        "import json\n",
        "from nltk import ngrams\n",
        "\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "from collections import Counter, defaultdict\n",
        "from google.colab import files, drive\n",
        "from typing import List, Dict, Tuple, DefaultDict, Union, Optional\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXsA5aR2V7ZD",
        "outputId": "a03cac62-4118-459b-faea-f37bd00a3fe4"
      },
      "outputs": [],
      "source": [
        "# connect to google drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9YuxEjjwj5Z"
      },
      "source": [
        "## Consts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NybZg_jywkFJ"
      },
      "outputs": [],
      "source": [
        "# Model Parameters\n",
        "BATCH_SIZE = 128\n",
        "HID_DIM    = 1024\n",
        "ENC_LAYERS = 6\n",
        "DEC_LAYERS = 6\n",
        "ENC_HEADS  = 4\n",
        "DEC_HEADS  = 4\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.0005\n",
        "CLIP = 1\n",
        "MAX_LENGTH = 50          # After MAX_LENGHT tokens are predicted by the model without reaching <eos>, it will stop trying\n",
        "N_EPOCHS = 150            # Train for how many epochs\n",
        "\n",
        "DATASET = 'dataset.json' # Name of the dataset to use, found in the Data repo under out_data\n",
        "USE_WANDBAI = False       # Use WANDBAI as a logging tool\n",
        "USE_COPY = True          # Train the models using a copy layer\n",
        "\n",
        "RANDOM = False           # Randomize the order of the entries\n",
        "LOWERCASE = False        # force lowercase for query and questions - \n",
        "                         # not recommended because it makes it very hard to go back to working SPARQL queries\n",
        "\n",
        "TAGS = ['dbr:', 'dbo:', 'dbp:', 'dbc:', 'dct:', 'geo:', 'georss:']\n",
        "\n",
        "DatasetIterator = torchtext.legacy.data.Dataset\n",
        "\n",
        "MODEL_TYPE = \"transformer\"\n",
        "COPY_FLAG = \"copy\" if USE_COPY else \"no_copy\"\n",
        "DATASET_FAMILY = \"Monument\"\n",
        "DATASET_NAME = \"mon_base_tagged_all_no_resources\" # DONT FORGET TO SET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYwW2oyaw0Wh"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B-4a0NCmjyG"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwZd2zJoP8D0"
      },
      "outputs": [],
      "source": [
        "# Translate a question into a sparql query\n",
        "def translate_sentence(tokens: Union[str, List[str]], \n",
        "                       src_field: Field,\n",
        "                       trg_field: Field,\n",
        "                       model: nn.Module,\n",
        "                       device: torch.device,\n",
        "                       max_len=MAX_LENGTH, \n",
        "                       predict_with_copy=USE_COPY) -> Tuple[List[str], int]:\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    # format as a list of strs\n",
        "    if isinstance(tokens, str):\n",
        "        tokens = tokenize_en(tokens)\n",
        "    if LOWERCASE:\n",
        "      tokens = [token.lower() for token in tokens]\n",
        "    print('1-TOKENS:', tokens)\n",
        "    # extend vocab with KB elems\n",
        "    if predict_with_copy:\n",
        "      resources_to_extend = extract_KB_elems(tokens)\n",
        "      print('2-RES TO EXTEND:', resources_to_extend)\n",
        "      KB_vocab = VocabDup(resources_to_extend, padding=0)\n",
        "      print('3-KB VOCAB:', KB_vocab.itos)\n",
        "\n",
        "\n",
        "      print('SRC FIELD BEFORE:', len(src_field.vocab))\n",
        "      print('TRG FIELD BEFORE:', len(trg_field.vocab))\n",
        "\n",
        "      src_field = extend_vocabulary(src_field, KB_vocab)\n",
        "      trg_field = extend_vocabulary(trg_field, KB_vocab)\n",
        "   \n",
        "      print('SRC FIELD AFTER:', len(src_field.vocab))\n",
        "      print('TRG FIELD AFTER:', len(trg_field.vocab))\n",
        "\n",
        "    # add <sos> and <eos> delimiters\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    print('4-TOKENS+SOS+EOS:', tokens)\n",
        "\n",
        "    # index sentence with extended src vocab\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    print('5-SRC_INDEXES:', src_indexes)\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    # make src_mask\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        print('... encoder')\n",
        "        enc_src = model.encoder(src_tensor.masked_fill(src_tensor >= model.encoder.tok_embedding.num_embeddings, 0), src_mask)\n",
        "\n",
        "    # init empty query sentence with only <sos> token\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "    # generate words\n",
        "    for i in range(max_len - 2):\n",
        "        print('6-TRG INDEXES:', trg_indexes)\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            print('\\t... decoder')\n",
        "            output, attention = model.decoder(trg_tensor.masked_fill(trg_tensor >= model.decoder.tok_embedding.num_embeddings, 0), enc_src, trg_mask, src_mask)\n",
        "            if predict_with_copy:\n",
        "              print('\\t... copy')\n",
        "              output, attention = model.copy_layer(src_tensor, output, attention)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    print('7-FINAL TRG INDEXES:', trg_indexes)\n",
        "    trg_tokens = [trg_field.vocab.itos[i] if i < len(trg_field.vocab) else '<unk>' for i in trg_indexes]\n",
        "    return trg_tokens[1:], attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcnIWKwdWrXm"
      },
      "outputs": [],
      "source": [
        "# Translate a question into a sparql query\n",
        "def batch_translate(batch: torch.Tensor,\n",
        "                    trg_field: Field,\n",
        "                    model: nn.Module,\n",
        "                    device: torch.device,\n",
        "                    max_len=MAX_LENGTH, \n",
        "                    predict_with_copy=USE_COPY) -> Tuple[List[str], int]:\n",
        "\n",
        "      model.eval()\n",
        "    \n",
        "      src_tensor = batch.English\n",
        "      src_mask = model.make_src_mask(src_tensor)\n",
        "        \n",
        "      with torch.no_grad():\n",
        "          enc_src = model.encoder(src_tensor.masked_fill(src_tensor >= model.encoder.tok_embedding.num_embeddings, 0), src_mask)\n",
        "\n",
        "\n",
        "      # init empty query sentence with only <sos> token\n",
        "      trg_tensor = torch.full((src_tensor.shape[0], 1), 2).to(device)\n",
        "\n",
        "      # generate words\n",
        "      for test in range(max_len - 2):\n",
        "          trg_mask = model.make_trg_mask(trg_tensor)\n",
        "          with torch.no_grad():\n",
        "              output, attention = model.decoder(trg_tensor.masked_fill(trg_tensor >= model.decoder.tok_embedding.num_embeddings, 0), enc_src, trg_mask, src_mask)\n",
        "              if predict_with_copy:\n",
        "                output, attention = model.copy_layer(src_tensor, output, attention)\n",
        "        \n",
        "          output = output[:, -1, :]\n",
        "          pred_token = output.argmax(1)\n",
        "          pred_token = torch.unsqueeze(pred_token, dim=1)\n",
        "          trg_tensor = torch.cat((trg_tensor, pred_token), dim=1)\n",
        "    \n",
        "      # remove after eos\n",
        "      out = []\n",
        "      for sent in trg_tensor.cpu().numpy():\n",
        "\n",
        "        if trg_field.vocab.stoi[trg_field.eos_token] in sent:\n",
        "          try:\n",
        "            eos_id = np.where(sent == trg_field.vocab.stoi[trg_field.eos_token])[0][0]\n",
        "            sent = sent[:eos_id]\n",
        "\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "        out.append([trg_field.vocab.itos[i] if i < len(trg_field.vocab) else '<unk>' for i in sent][1:])\n",
        "    \n",
        "      return out, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oGBuJHgMGHz"
      },
      "outputs": [],
      "source": [
        "# Calculate the BLEU score of our test set by batch\n",
        "def batch_bleu(iterator: DatasetIterator, \n",
        "               trg_field: Field, # use BASE_TRG for syntax!\n",
        "               model: nn.Module,\n",
        "               device: torch.device,\n",
        "               use_copy=USE_COPY) -> float:\n",
        "\n",
        "    bleu_preds = []\n",
        "    bleu_expected = []\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "      preds, _ = batch_translate(batch, trg_field, model, device, predict_with_copy=use_copy)\n",
        "      bleu_preds.extend(preds)\n",
        "      expected = get_batch_tokens(batch.SPARQL[:,1:-1], trg_field)\n",
        "      bleu_expected.extend(expected)\n",
        "\n",
        "    return bleu_score(bleu_preds, [[sent] for sent in bleu_expected])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxkKce8uMKJK"
      },
      "outputs": [],
      "source": [
        "# Convert a batch of token ids to a batch of tokens (by Samuel)\n",
        "def get_batch_tokens(batch: torch.Tensor, field: Field) -> List[str]:\n",
        "    output_tokens = []\n",
        "    for pred_trg in batch:\n",
        "        eos_ids = (pred_trg == field.vocab.stoi[field.eos_token]).nonzero(as_tuple=True)[0]\n",
        "  \n",
        "        if eos_ids.nelement():\n",
        "            non_eos_tokens_ids = pred_trg[:eos_ids[0]]\n",
        "        else:\n",
        "            non_eos_tokens_ids = pred_trg\n",
        "        \n",
        "        output_tokens.append([field.vocab.itos[tok] if tok <= len(field.vocab) else '<unk>' for tok in non_eos_tokens_ids])\n",
        "    return output_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFOqtdhU8MHw"
      },
      "outputs": [],
      "source": [
        "# Calculate the BLEU score of our test set\n",
        "def calculate_bleu(data: DatasetIterator, \n",
        "                   src_field: Field, \n",
        "                   trg_field: Field, \n",
        "                   model: nn.Module, \n",
        "                   device: torch.device,\n",
        "                   predict_with_copy=USE_COPY, \n",
        "                   max_len=MAX_LENGTH) -> Tuple[float, float]:\n",
        "    print(\"Calculating BLEU score...\")\n",
        "    expected_trgs = []\n",
        "    pred_trgs = []\n",
        "    pred_copy_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "        src = vars(datum)['English']\n",
        "        trg = vars(datum)['SPARQL']\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len, predict_with_copy=predict_with_copy)\n",
        "        if pred_trg[-1] is trg_field.eos_token:\n",
        "          pred_trg = pred_trg[:-1]\n",
        "        pred_trgs.append(pred_trg)\n",
        "        expected_trgs.append([trg])\n",
        "        \n",
        "    return bleu_score(pred_trgs, expected_trgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW_DeKbvgu9E"
      },
      "outputs": [],
      "source": [
        "# Calculate the BLEU score of our test set - when using copy we want syntax\n",
        "def calculate_bleu_syntax(data: DatasetIterator, \n",
        "                          src_field: Field, \n",
        "                          trg_field: Field, \n",
        "                          model: nn.Module, \n",
        "                          device: torch.device, \n",
        "                          max_len=MAX_LENGTH) -> float:\n",
        "    print(\"Calculating BLEU score of syntax...\")\n",
        "    expected_trgs = []\n",
        "    expected_syntax = []\n",
        "    pred_trgs_syntax = []\n",
        "    pred_copy_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "        src = vars(datum)['English']\n",
        "        trg = vars(datum)['SPARQL']\n",
        "        pred_syntax, _ = translate_sentence(src, src_field, trg_field, model, device, max_len, predict_with_copy=True)\n",
        "        if pred_syntax[-1] is trg_field.eos_token:\n",
        "          pred_syntax = pred_syntax[:-1]\n",
        "\n",
        "        pred_trgs_syntax.append(pred_syntax)\n",
        "\n",
        "        trg_syntax = ['<unk>' if token.startswith(tuple(TAGS)) else token for token in trg]\n",
        "        expected_syntax.append([trg_syntax])\n",
        "\n",
        "    return bleu_score(pred_trgs_syntax, expected_syntax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp03pYcVN6_E"
      },
      "outputs": [],
      "source": [
        "# calculates some metrics on the test set\n",
        "def get_metrics(data: DatasetIterator,\n",
        "                test_entries: List[Dict], \n",
        "                src_field: Field, \n",
        "                trg_field: Field, \n",
        "                model: nn.Module,\n",
        "                device: torch.device, \n",
        "                max_len=MAX_LENGTH, \n",
        "                predict_with_copy=USE_COPY) -> Dict[str, float]:\n",
        "    print(\"Computing evaluation metrics...\")\n",
        "    expected_trgs = []\n",
        "    pred_trgs = []\n",
        "    error_report = []\n",
        "\n",
        "    for i, datum in enumerate(data):\n",
        "        src = vars(datum)['English']\n",
        "        trg = vars(datum)['SPARQL']\n",
        "\n",
        "        pred_trg, _ = translate_sentence(src, src_field, trg_field, model, device, max_len, predict_with_copy)\n",
        "\n",
        "        pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        expected_trgs.append([trg])\n",
        "\n",
        "        error_entry = {\n",
        "            'id': test_entries[i]['_id'],\n",
        "            'template_id': test_entries[i]['template_id'],\n",
        "            'src': ' '.join(src),\n",
        "            'trg': ' '.join(trg),\n",
        "            'predicted': ' '.join(pred_trg),\n",
        "            'correct': trg == pred_trg\n",
        "        }\n",
        "        error_report.append(error_entry)\n",
        "\n",
        "    metrics = {}\n",
        "    nb_examples = len(expected_trgs)\n",
        "    metrics['bleu'] = bleu_score(pred_trgs, expected_trgs)\n",
        "    metrics['accuracy'] = sum([int(pred_trgs[i] == expected_trgs[i][0]) for i in range(nb_examples)])/nb_examples\n",
        "\n",
        "    pred_ngrams = [list(ngrams_iterator(pred, len(pred))) for pred in pred_trgs]\n",
        "    exp_ngrams = [list(ngrams_iterator(exp[0], len(exp[0]))) for exp in expected_trgs]\n",
        "\n",
        "    #https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
        "    n_commons = [len(set(pred_ngrams[i]) & set(exp_ngrams[i])) for i in range(nb_examples)]\n",
        "\n",
        "    recalls = [n_commons[i] / len(exp_ngrams[i]) for i in range(nb_examples)]\n",
        "    metrics['macro recall'] = sum(recalls) / len(recalls)\n",
        "\n",
        "    precisions = [n_commons[i] / len(pred_ngrams[i]) for i in range(nb_examples)]\n",
        "    metrics['macro precision'] = sum(precisions) / len(precisions)\n",
        "\n",
        "    metrics['f1 score'] = 2 * (metrics['macro precision'] * metrics['macro recall']) / (metrics['macro precision'] + metrics['macro recall'])\n",
        "\n",
        "    with open('out/error_report.json', 'w', encoding='utf-8') as f:\n",
        "      json.dump(error_report, f, indent=4)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDqdCAT3N04k"
      },
      "source": [
        "### Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kKj09qiOmRJ"
      },
      "outputs": [],
      "source": [
        "# imitation of a torchtext.vocab.Vocab, basic structure needed to extend a torchtext Vocab\n",
        "class VocabDup:\n",
        "  def __init__(self, vocab: Union[Dict[int, str], List[str]], padding=0, base_vocab_size=0):\n",
        "    if type(vocab) is list:\n",
        "      self.make_vocab_from_list(vocab, padding)\n",
        "\n",
        "    elif type(vocab) is dict:\n",
        "      self.make_vocab_from_dict(vocab, base_vocab_size)\n",
        "    \n",
        "    else:\n",
        "      raise ValueError(\"Could not make a vocab from this structure\")\n",
        "\n",
        "\n",
        "  # Make vocab from a list (usually KB elem list) to use it to extend base vocabs\n",
        "  def make_vocab_from_list(self, word_list: List[str], padding=0) -> None:\n",
        "      word_list = list(set(word_list))\n",
        "      word_counter = Counter(word_list)\n",
        "      stoi = defaultdict(int)\n",
        "      itos = [None for _ in range(len(word_list) + padding)]\n",
        "\n",
        "      curr_idx = 0\n",
        "      # pad if necessary\n",
        "      for i in range(padding):\n",
        "          word = f'not_a_resource_{i}'\n",
        "        \n",
        "          stoi[word] = curr_idx\n",
        "          itos[curr_idx] = word\n",
        "          curr_idx+=1\n",
        "\n",
        "      # add KB elems\n",
        "      for word in word_counter:\n",
        "          stoi[word] = curr_idx\n",
        "          itos[curr_idx] = word\n",
        "          curr_idx+=1\n",
        "\n",
        "      self.freq = word_counter\n",
        "      self.itos = itos\n",
        "      self.stoi = stoi\n",
        "\n",
        "  # Make vocab from a dict (usually when loading the vocab files)\n",
        "  def make_vocab_from_dict(self, word_dict: Dict[int, str], base_vocab_size: int=0) -> None:\n",
        "      stoi = defaultdict(int)\n",
        "      base_vocab_size = len(word_dict.values()) if base_vocab_size < 1 else base_vocab_size\n",
        "      itos = [None for _ in range(base_vocab_size)]\n",
        "\n",
        "      for idx, word in word_dict.items():\n",
        "          if idx < base_vocab_size:\n",
        "              stoi[word] = idx\n",
        "              itos[idx] = word\n",
        "\n",
        "      word_counter = Counter(itos)\n",
        "\n",
        "      self.freq = word_counter\n",
        "      self.itos = itos\n",
        "      self.stoi = stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_ZuhuxLX_CI"
      },
      "outputs": [],
      "source": [
        "# by samuel\n",
        "def hide_KB_elems(tokens: List[str], unk_token = '<unk>') -> List[str]:\n",
        "  return [unk_token if token.startswith(tuple(TAGS)) else token for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuhKzm564Uga"
      },
      "outputs": [],
      "source": [
        "# Extract KB elements from a tokenized sentence\n",
        "def extract_KB_elems(tokens: List[str]) -> List[str]:\n",
        "  removed_resources_en = [t for t in tokens if t.startswith(tuple(TAGS))]\n",
        "  return removed_resources_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EdQwDTdV5jj"
      },
      "outputs": [],
      "source": [
        "# This function acts exactly like the PyTorch version, but using the PyTorch version Field.vocab.extend_vocabulary cause\n",
        "# some seriously weird bugs. Our best guess was that it caused collisions in the dict keys, but it is highly unlikely\n",
        "def extend_vocabulary(field: Field, extension: VocabDup) -> Field:\n",
        "    words = extension.itos\n",
        "    for w in words:\n",
        "        if w not in field.vocab.itos: # stoi does not work\n",
        "            field.vocab.itos.append(w)\n",
        "            field.vocab.stoi[w] = len(field.vocab.itos) - 1\n",
        "\n",
        "    return field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JACtiMppFwIZ"
      },
      "outputs": [],
      "source": [
        "# It is possible that a query contains a KB elem that is in the KB vocab but not in the question (for example, LC-QuAD template ID 7)\n",
        "# In that case, we should replace KB elems that are not in BOTH the query and the question by unknown tokens (0)\n",
        "def fix_extended_vocab(src: List[List[int]], trg: List[List[int]], base_voc_limit_trg: int, unk_token = 0) -> List[List[int]]:\n",
        "  for i_s, sentence in enumerate(trg): # batch size\n",
        "    for i_t, token_idx in enumerate(trg[i_s]): # batch size\n",
        "      if token_idx >= base_voc_limit_trg and token_idx not in src[i_s]:\n",
        "        trg[i_s][i_t] = unk_token\n",
        "\n",
        "  return trg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IsW6VuXzIlv"
      },
      "outputs": [],
      "source": [
        "# Save vocab to reuse for inference\n",
        "def save_vocab(vocab: torchtext.vocab.Vocab, path: str) -> None:\n",
        "    with open(path, 'w', encoding='utf-8') as f:     \n",
        "        for token, index in vocab.stoi.items():\n",
        "            f.write(f'{index}\\t{token}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zReT0YM97IcZ"
      },
      "outputs": [],
      "source": [
        "# Read vocab files\n",
        "def read_vocab(path: str) -> Dict[int, str]:\n",
        "    voc = {}\n",
        "    i = 0\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read().splitlines()\n",
        "        for line in data:\n",
        "            index, token = line.split('\\t')\n",
        "            voc[i] = token\n",
        "            i += 1\n",
        "    return voc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waUyJHgiOk7K"
      },
      "outputs": [],
      "source": [
        "# Split vocbaularies: keep only the base words of question and queries, and save all removed KB elems in another list\n",
        "def abstract_KB_elems(data) -> Tuple[Dict, Dict]:\n",
        "  base_vocabs = {'English': [], 'SPARQL': []}\n",
        "  kb_vocabs = {'English': [], 'SPARQL': []}\n",
        "\n",
        "  for example in data:\n",
        "    nl = example.English\n",
        "    sparql = example.SPARQL\n",
        "\n",
        "    # for nl\n",
        "    filtered_nl = [t for t in nl if not t.startswith(tuple(TAGS))]\n",
        "    removed_resources_nl = [t for t in nl if t.startswith(tuple(TAGS))]\n",
        "\n",
        "    # for sparql\n",
        "    filtered_sparql = [t for t in sparql if not t.startswith(tuple(TAGS))]\n",
        "    removed_resources_sparql = [t for t in sparql if t.startswith(tuple(TAGS))]\n",
        "\n",
        "    # keep separated by sentences\n",
        "    base_vocabs['English'].append(filtered_nl)\n",
        "    base_vocabs['SPARQL'].append(filtered_sparql)\n",
        "\n",
        "    # a single list of all KB elems\n",
        "    kb_vocabs['English'].extend(removed_resources_nl)\n",
        "    kb_vocabs['SPARQL'].extend(removed_resources_sparql)\n",
        "\n",
        "  return base_vocabs, kb_vocabs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCRXHgSPOcBs"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukw6vrwcTgSC"
      },
      "outputs": [],
      "source": [
        "# Tokenize a question by splitting at spaces\n",
        "def tokenize_en(text: str) -> List[str]:\n",
        "    splitted = text.split()\n",
        "    return [w for w in splitted if len(w) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNj_GMXrTiaG"
      },
      "outputs": [],
      "source": [
        "# Tokenize a query by splitting at spaces\n",
        "def tokenize_sparql(text: str) -> List[str]:\n",
        "    splitted = text.split()\n",
        "    return [w for w in splitted if len(w) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxvsMg2YOfiQ"
      },
      "outputs": [],
      "source": [
        "# Generate train, val and test sets\n",
        "def gen_train_test_val_sets(train_examples: List[str], \n",
        "                            valid_examples: List[str], \n",
        "                            test_examples: List[str], \n",
        "                            data_fields: List[Tuple[str, Field]]) -> Tuple[TabularDataset, TabularDataset, TabularDataset]:\n",
        "    train_set = pd.DataFrame(train_examples, columns=[\"English\", \"SPARQL\"])\n",
        "    valid_set = pd.DataFrame(valid_examples, columns=[\"English\", \"SPARQL\"])\n",
        "    test_set = pd.DataFrame(test_examples, columns=[\"English\", \"SPARQL\"])\n",
        "\n",
        "    train_set = pd.DataFrame(train_set, columns=[\"English\", \"SPARQL\"])\n",
        "    valid_set = pd.DataFrame(valid_set, columns=[\"English\", \"SPARQL\"])\n",
        "    test_set = pd.DataFrame(test_set, columns=[\"English\", \"SPARQL\"])\n",
        "\n",
        "    train_set.to_csv(\"train.csv\", index=False, header=None)\n",
        "    valid_set.to_csv(\"valid.csv\", index=False, header=None)\n",
        "    test_set.to_csv(\"test.csv\", index=False, header=None)\n",
        "\n",
        "    train_data, valid_data, test_data = torchtext.legacy.data.TabularDataset.splits(\n",
        "        path='./', train='train.csv', validation='valid.csv', test='test.csv', format='csv', fields=data_fields)\n",
        "\n",
        "    return train_data, valid_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XkDjq_GTrIL"
      },
      "outputs": [],
      "source": [
        "# Generate the data fields used to encode the question-query pairs\n",
        "def gen_data_field() -> Tuple[Field, Field]:\n",
        "    SRC = Field(tokenize=tokenize_en,\n",
        "                init_token='<sos>',\n",
        "                eos_token='<eos>',\n",
        "                lower=LOWERCASE,\n",
        "                batch_first=True)\n",
        "\n",
        "    TRG = Field(tokenize=tokenize_sparql,\n",
        "                init_token='<sos>',\n",
        "                eos_token='<eos>',\n",
        "                lower=LOWERCASE,\n",
        "                batch_first=True)\n",
        "\n",
        "    return SRC, TRG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdhsqM5rOFy9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rFK2SioT3nD"
      },
      "outputs": [],
      "source": [
        "# Initialize model weights\n",
        "def initialize_weights(m) -> None:\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6z4uRMi7U1mE"
      },
      "outputs": [],
      "source": [
        "# Count number of parameters in the model\n",
        "def count_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdObPd-UVJc8"
      },
      "outputs": [],
      "source": [
        "# Calculate epoch duration\n",
        "def epoch_time(start_time: float, end_time: float) -> Tuple[float, float]:\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETHixOZQxYpM"
      },
      "outputs": [],
      "source": [
        "# Training function of the model\n",
        "def train(model: nn.Module, \n",
        "          iterator: DatasetIterator, \n",
        "          optimizer: torch.optim.Optimizer, \n",
        "          criterion: nn.Module, clip: float, \n",
        "          use_copy=USE_COPY) -> float:\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = []\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.English\n",
        "        trg = batch.SPARQL\n",
        "        \n",
        "        if use_copy: \n",
        "          trg = fix_extended_vocab(src, trg, OUT_TRG_DIM)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "        output_dim = output.shape[-1]\n",
        "           \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1) \n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += [loss.item()]\n",
        "\n",
        "    return epoch_loss[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GugzvWMVVKKX"
      },
      "outputs": [],
      "source": [
        "# Eval function of the model\n",
        "def evaluate(model: nn.Module, \n",
        "             iterator: DatasetIterator, \n",
        "             criterion: nn.Module, \n",
        "             use_copy=USE_COPY) -> float:\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.English\n",
        "            trg = batch.SPARQL\n",
        "\n",
        "            if use_copy: \n",
        "              trg = fix_extended_vocab(src, trg, OUT_TRG_DIM)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += [loss.item()]\n",
        "        \n",
        "    return epoch_loss[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgPa4_jZxtvM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXx2MVnwxyjU"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim:int, \n",
        "                 n_heads:int, \n",
        "                 dropout:float, \n",
        "                 device: torch.device):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        assert hid_dim % n_heads == 0\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, \n",
        "                query: torch.Tensor, \n",
        "                key: torch.Tensor, \n",
        "                value: torch.Tensor, \n",
        "                mask=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        Q = Q.view(batch_size, -1, self.n_heads,\n",
        "                   self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads,\n",
        "                   self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads,\n",
        "                   self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        return x, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6RSL4ZAx1LA"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim: int, \n",
        "                 pf_dim: int, \n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        x = self.fc_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnBQ7KYWVupz"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim: int,\n",
        "                 n_heads: int,\n",
        "                 pf_dim: int,\n",
        "                 dropout: float,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(\n",
        "            hid_dim, n_heads, dropout, device) \n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, \n",
        "                src: torch.Tensor,\n",
        "                src_mask: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCJvyjQwxil9"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim: int, \n",
        "                 hid_dim: int, \n",
        "                 n_layers: int,\n",
        "                 n_heads: int, \n",
        "                 pf_dim: int, \n",
        "                 dropout: float, \n",
        "                 device: torch.device, \n",
        "                 max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, \n",
        "                src: torch.Tensor, \n",
        "                src_mask: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(\n",
        "            0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        src = self.dropout(\n",
        "            (self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        return src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzRn1culWOL3"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hid_dim: int,\n",
        "                 n_heads: int,\n",
        "                 pf_dim: int,\n",
        "                 dropout: float,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(\n",
        "            hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(\n",
        "            hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim,\n",
        "                                                                     pf_dim,\n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, \n",
        "                trg: torch.Tensor, \n",
        "                enc_src: torch.Tensor, \n",
        "                trg_mask: torch.Tensor, \n",
        "                src_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        # self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # encoder attention\n",
        "        _trg, attention = self.encoder_attention(\n",
        "            trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        return trg, attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNOhsbcxx6P8"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 hid_dim: int,\n",
        "                 n_layers: int,\n",
        "                 n_heads: int,\n",
        "                 pf_dim: int,\n",
        "                 dropout: float,\n",
        "                 device: torch.device,\n",
        "                 max_length=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim,\n",
        "                                                  n_heads,\n",
        "                                                  pf_dim,\n",
        "                                                  dropout,\n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "        self.dropout_val = dropout\n",
        "\n",
        "        self.dropout = nn.Dropout(self.dropout_val)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    def forward(self, \n",
        "                trg: torch.Tensor, \n",
        "                enc_src: torch.Tensor, \n",
        "                trg_mask: torch.Tensor, \n",
        "                src_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(\n",
        "            0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        trg = self.dropout(\n",
        "            (self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        return output, attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7qJS-zgnDja"
      },
      "outputs": [],
      "source": [
        "class CopyLayerVocabExtend(nn.Module):\n",
        "  def __init__(self, decoder: Decoder):\n",
        "    super().__init__()\n",
        "    self.switch = nn.Linear(decoder.tok_embedding.num_embeddings, 1)\n",
        "\n",
        "  def forward(self, \n",
        "              src: torch.Tensor, \n",
        "              output: torch.Tensor, \n",
        "              attention: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    p_pointer = torch.sigmoid(self.switch(output))\n",
        "\n",
        "    # src -> [2, 23, 1129, 40, 1083, 11, 3]\n",
        "    # output = trg_predit -> [2, 45, 35, 1129, 40, 1083, 12, 3]\n",
        "    \n",
        "    if torch.max(src) + 1 > output.shape[-1]: # mots inconnus dans source?\n",
        "      extended = Variable(torch.zeros((output.shape[0], output.shape[1], torch.max(src) + 1 - output.shape[-1]))).to(output.device)\n",
        "      output = torch.cat((output, extended), dim = 2)\n",
        "\n",
        "    output = ((1 - p_pointer) * F.softmax(output, dim = 2)).scatter_add(2, src.unsqueeze(1).repeat(1, output.shape[1], 1), p_pointer * attention[:, 3]) + 1e-10\n",
        "    # output = trg_predit -> [2, 45, 35, 1129, 40, 1083, 12, 3]\n",
        "    return torch.log(output), attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq5P4Qe4x7ic"
      },
      "outputs": [],
      "source": [
        "class TransfSeq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: Encoder,\n",
        "                 decoder: Decoder,\n",
        "                 src_pad_idx: int,\n",
        "                 trg_pad_idx: int,\n",
        "                 device: torch.device,\n",
        "                 copy_layer: CopyLayerVocabExtend =None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "        self.copy_layer = copy_layer\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        trg_sub_mask = torch.tril(torch.ones(\n",
        "            (trg_len, trg_len), device=self.device)).bool()\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        if self.copy_layer is None:\n",
        "          source = self.encoder(src, src_mask)\n",
        "          output, attention = self.decoder(trg, source, trg_mask, src_mask)\n",
        "          return output, attention\n",
        "\n",
        "        else: # avec copie\n",
        "          # src -> [2, 23, 1129, 40, 1083, 11, 3]\n",
        "          # trg -> [2, 45, 34, 1129, 40, 1083, 12, 3]\n",
        "\n",
        "          # src -> [2, 23, 0, 40, 0, 11, 3]\n",
        "          source = self.encoder(src.masked_fill(src >= self.encoder.tok_embedding.num_embeddings, 0), src_mask)\n",
        "\n",
        "          # trg -> [2, 45, 34, 0, 40, 0, 12, 3]\n",
        "          output, attention = self.decoder(trg.masked_fill(trg >= self.decoder.tok_embedding.num_embeddings, 0), source, trg_mask, src_mask)\n",
        "\n",
        "\n",
        "          # src -> [2, 23, 1129, 40, 1083, 11, 3]\n",
        "          # output = trg_predit -> [2, 45, 35, 0, 40, 0, 12, 3]\n",
        "          output, attention = self.copy_layer(src, output, attention)\n",
        "          return output, attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFCnx-I6HPpX"
      },
      "source": [
        "# INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T29rWyf7FwxD"
      },
      "outputs": [],
      "source": [
        "ITERATION = 1\n",
        "OUT_DRIVE_FOLDER_BASE = f\"/content/gdrive/MyDrive/PRETRAINED/{MODEL_TYPE}/{COPY_FLAG}/{DATASET_FAMILY}/{DATASET_NAME}/{ITERATION}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8lgEnh8IxK5"
      },
      "outputs": [],
      "source": [
        "CONFIG_PATH = f'{OUT_DRIVE_FOLDER_BASE}/config.json'\n",
        "SRC_VOCAB_PATH = f'{OUT_DRIVE_FOLDER_BASE}/src_vocab.field'\n",
        "TRG_VOCAB_PATH = f'{OUT_DRIVE_FOLDER_BASE}/trg_vocab.field'\n",
        "MODEL_PATH = f'{OUT_DRIVE_FOLDER_BASE}/best-model-state-dict.pt'\n",
        "OOV_DATASET = 'oov_dataset.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jChCcCaDi_B-"
      },
      "outputs": [],
      "source": [
        "# Translator class to facilitate inference, easier portability\n",
        "# If you use it as a standalone script, make sure to also import the following utils elements:\n",
        "# VocabDub, gen_data_field(), read_vocab(), extend_vocabulary(), translate_sentence()\n",
        "# As well as the model architecture:\n",
        "# Encoder, Decoder, CopyLayerVocabExtend and CNNSeq2Seq\n",
        "\n",
        "class Translator:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        with open(CONFIG_PATH, 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        base_vocab_size = max(config['INPUT_DIM'], config['OUTPUT_DIM'])\n",
        "\n",
        "        # load vocab\n",
        "        self.SRC, self.TRG = gen_data_field()\n",
        "        self.SRC.build_vocab([], min_freq=1, max_size=None)\n",
        "        self.TRG.build_vocab([], min_freq=1, max_size=None)\n",
        "\n",
        "        src_vocab = VocabDup(read_vocab(SRC_VOCAB_PATH), base_vocab_size)\n",
        "        trg_vocab = VocabDup(read_vocab(TRG_VOCAB_PATH), base_vocab_size)\n",
        "\n",
        "        self.SRC = extend_vocabulary(self.SRC, src_vocab)\n",
        "        self.TRG = extend_vocabulary(self.TRG, trg_vocab)\n",
        "        \n",
        "        # define model\n",
        "        self.enc = Encoder(\n",
        "            config['INPUT_DIM'], config['HID_DIM'], \n",
        "            config['ENCODER']['ENC_LAYERS'], config['ENCODER']['ENC_HEADS'], \n",
        "            config['ENCODER']['ENC_PF_DIM'], config['ENCODER']['ENC_DROPOUT'], self.device)\n",
        "  \n",
        "        self.dec = Decoder(config['OUTPUT_DIM'], config['HID_DIM'], \n",
        "                           config['DECODER']['DEC_LAYERS'], config['DECODER']['DEC_HEADS'], \n",
        "                           config['DECODER']['DEC_PF_DIM'], config['DECODER']['DEC_DROPOUT'], self.device)\n",
        "\n",
        "        self.copy_layer = CopyLayerVocabExtend(self.dec) if config['USE_COPY'] else None\n",
        "        self.model = TransfSeq2Seq(self.enc, self.dec, config['SRC_PAD_IDX'], config['TRG_PAD_IDX'], self.device, self.copy_layer).to(self.device)\n",
        "\n",
        "        # load pretrained model\n",
        "        loaded = torch.load(MODEL_PATH)\n",
        "        self.model.load_state_dict(loaded)\n",
        "        self.model.eval()\n",
        "   \n",
        "    def translate(self, sentence: str) -> List[str]:\n",
        "      translation, _ = translate_sentence(\n",
        "          sentence.split(), self.SRC, self.TRG, self.model, self.device, predict_with_copy=self.model.copy_layer is not None)\n",
        "      \n",
        "      return translation\n",
        "\n",
        "    def calculate_bleu(self, test_data: List[Dict]) -> float:\n",
        "      print(\"Calculating BLEU score...\")\n",
        "\n",
        "      expected_trgs = []\n",
        "      pred_trgs = []\n",
        "      pred_copy_trgs = []\n",
        "      error_report = []\n",
        "\n",
        "      for entry in test_data:\n",
        "          src_sentence = entry['question']['uri_question_rest_no_resources']\n",
        "          trg_sentence = entry['query']['uri_interm_sparql_rest_no_resources']\n",
        "          \n",
        "          pred_trg = self.translate(src_sentence)\n",
        "          print(\"OUT:\", pred_trg)\n",
        "          die()\n",
        "          pred_trg = pred_trg[:-1]\n",
        "          pred_trgs.append(pred_trg)\n",
        "          expected_trgs.append([trg_sentence.split()])\n",
        "\n",
        "          error_entry = {\n",
        "            'id': entry['_id'],\n",
        "            'template_id': entry['template_id'],\n",
        "            'src': src_sentence,\n",
        "            'trg': trg_sentence,\n",
        "            'predicted': ' '.join(pred_trg),\n",
        "            'correct': trg_sentence == pred_trg\n",
        "          }\n",
        "\n",
        "          error_report.append(error_entry)\n",
        "\n",
        "      bleu = bleu_score(pred_trgs, expected_trgs)\n",
        "\n",
        "      with open(f'{OUT_DRIVE_FOLDER_BASE}/error_report_oov.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(error_report, f, indent=4)\n",
        "\n",
        "      return bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXc2Yd-eZUFi",
        "outputId": "edde90a7-520f-4c7b-da5d-67e84887b0d1"
      },
      "outputs": [],
      "source": [
        "translator = Translator()\n",
        "\n",
        "with open(OOV_DATASET, 'r', encoding='utf-8') as f:\n",
        "  dataset = json.load(f)\n",
        "  \n",
        "print(translator.calculate_bleu(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiZ2TMNafC4M"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uYwW2oyaw0Wh",
        "5B-4a0NCmjyG",
        "HDqdCAT3N04k",
        "DCRXHgSPOcBs",
        "FdhsqM5rOFy9",
        "DgPa4_jZxtvM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
