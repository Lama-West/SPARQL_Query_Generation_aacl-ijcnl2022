{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twE0CjlZ5svD",
        "outputId": "a37978da-80e0-4bdc-e22e-bc6f82841b3c"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install SPARQLWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT_50aM95Hku"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any, Tuple, Union\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from tqdm import tqdm\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "from google.colab import files, drive\n",
        "import ssl\n",
        "import glob\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvLRklGs8BZY",
        "outputId": "17b920a9-617a-4534-aaf9-f0490b26f2c7"
      },
      "outputs": [],
      "source": [
        "# connect to google drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv1bgxw1zkfC"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = \"transformer\" # cnns2s or transformer\n",
        "COPY_FLAG = \"copy\" # or no_copy\n",
        "DATASET_FAMILY = \"LC-QuAD\" # Monument or LC-QuAD\n",
        "DATASET_NAME = \"intermediary_question_tagged_all\" # DONT FORGET TO SET\n",
        "MODELS_FOLDER = f\"/content/gdrive/MyDrive/PRETRAINED/{MODEL_TYPE}/{COPY_FLAG}/{DATASET_FAMILY}/{DATASET_NAME}/\"\n",
        "\n",
        "REPORT_FILENAME = 'error_report.json'\n",
        "\n",
        "REGENERATE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9YuxEjjwj5Z"
      },
      "source": [
        "## Consts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NybZg_jywkFJ"
      },
      "outputs": [],
      "source": [
        "REPLACEMENTS = [\n",
        "    ['dbo:', 'http://dbpedia.org/ontology/', 'dbo_'],\n",
        "    ['dbp:', 'http://dbpedia.org/property/', 'dbp_'],\n",
        "    ['dbc:', 'http://dbpedia.org/resource/Category:', 'dbc_'],\n",
        "    ['dbr:', 'res:', 'http://dbpedia.org/resource/', 'dbr_'],\n",
        "    ['dct:', 'dct_'],\n",
        "    ['geo:', 'geo_'],\n",
        "    ['georss:', 'georss_'],\n",
        "    ['rdf:', 'rdf_'],\n",
        "    ['rdfs:', 'rdfs_'],\n",
        "    ['foaf:', 'foaf_'],\n",
        "    ['owl:', 'owl_'],\n",
        "    ['yago:', 'yago_'],\n",
        "    ['skos:', 'skos_'],\n",
        "    [' ( ', '  par_open  '],\n",
        "    [' ) ', '  par_close  '],\n",
        "    [' ( ', ' sparql_open '],\n",
        "    [' ) ', ' sparql_close '],\n",
        "    ['(', ' attr_open '],\n",
        "    [') ', ')', ' attr_close '],\n",
        "    ['{', ' brack_open '],\n",
        "    ['}', ' brack_close '],\n",
        "    [' . ', ' sep_dot '],\n",
        "    ['. ', ' sep_dot '],\n",
        "    ['?', 'var_'],\n",
        "    ['*', 'wildcard'],\n",
        "    [' <= ', ' math_leq '],\n",
        "    [' >= ', ' math_geq '],\n",
        "    [' < ', ' math_lt '],\n",
        "    [' > ', ' math_gt ']\n",
        "]\n",
        "\n",
        "\n",
        "URI_SHORTENERS = [\n",
        "    {\n",
        "        'match': 'http://dbpedia.org/ontology/',\n",
        "        'interm_sparql': 'dbo_',\n",
        "        'pure_sparql': 'dbo:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'http://dbpedia.org/property/',\n",
        "        'interm_sparql': 'dbp_',\n",
        "        'pure_sparql': 'dbp:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'http://dbpedia.org/resource/Category:',\n",
        "        'interm_sparql': 'dbc_',\n",
        "        'pure_sparql': 'dbc:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'http://dbpedia.org/resource/',\n",
        "        'interm_sparql': 'dbr_',\n",
        "        'pure_sparql': 'dbr:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'dbo:',\n",
        "        'interm_sparql': 'dbo_',\n",
        "        'pure_sparql': 'dbo:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'dbp:',\n",
        "        'interm_sparql': 'dbp_',\n",
        "        'pure_sparql': 'dbp:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'dbc:',\n",
        "        'interm_sparql': 'dbc_',\n",
        "        'pure_sparql': 'dbc:'\n",
        "    },\n",
        "    {\n",
        "        'match': 'dbr:',\n",
        "        'interm_sparql': 'dbr_',\n",
        "        'pure_sparql': 'dbr:'\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "PURE_SPARQL_TO_INTERM = [\n",
        "    {\n",
        "        'pure_sparql': 'dct:',\n",
        "        'interm_sparql': 'dct_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'geo:',\n",
        "        'interm_sparql': 'geo_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'georss:',\n",
        "        'interm_sparql': 'georss_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'rdf:',\n",
        "        'interm_sparql': 'rdf_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'rdfs:',\n",
        "        'interm_sparql': 'rdfs_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'foaf:',\n",
        "        'interm_sparql': 'foaf_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'owl:',\n",
        "        'interm_sparql': 'owl_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'yago:',\n",
        "        'interm_sparql': 'yago_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': 'skos:',\n",
        "        'interm_sparql': 'skos_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '(',\n",
        "        'interm_sparql': '  par_open  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ')',\n",
        "        'interm_sparql': '  par_close  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '{',\n",
        "        'interm_sparql': '  brack_open  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '}',\n",
        "        'interm_sparql': '  brack_close  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '.',\n",
        "        'interm_sparql': '  sep_dot  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '?',\n",
        "        'interm_sparql': ' var_'\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': '*',\n",
        "        'interm_sparql': '  wildcard  '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ' <= ',\n",
        "        'interm_sparql': ' math_leq '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ' >= ',\n",
        "        'interm_sparql': ' math_geq '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ' < ',\n",
        "        'interm_sparql': ' math_lt '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ' > ',\n",
        "        'interm_sparql': ' math_gt '\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "PURE_SPARQL_TO_INTERM_RES = [\n",
        "    {\n",
        "        'pure_sparql': '(',\n",
        "        'interm_sparql': ' attr_open '\n",
        "    },\n",
        "    {\n",
        "        'pure_sparql': ')',\n",
        "        'interm_sparql': ' attr_close '\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "PLACEHOLDERS = {\n",
        "    'dbo': '<ontology>',\n",
        "    'dbp': '<property>',\n",
        "    'dbc': '<category>',\n",
        "    'dbr': '<resource>'\n",
        "}\n",
        "\n",
        "# when replacing var_uri by ?uri, sometimes catches resources containing var (ex: Sarovar_Bridge becomes Saro?Bridge). This regex is used to revert this change in resources but not in variables\n",
        "CATCH_VAR_IN_RESOURCE_NAME_RE = re.compile('db[rocp]:[a-zA-Z0-9_]*?(\\?)[a-zA-Z0-9]', flags = re.IGNORECASE)\n",
        "\n",
        "# in interm sparql, ORDER BY DESC(?uri)  become _obd_ var_uri\n",
        "REPLACE_ORDER_BY_RE = re.compile(\".*((_ob[ad]_)\\\\s*(\\\\?[a-zA-Z]+))\", flags = re.IGNORECASE)\n",
        "\n",
        "# Catch resources in pure sparql queries\n",
        "GET_RESOURCES_PURE_SPARQL_RE = re.compile(\"(db[orcp]:.*?)(?:[\\s|}])\", flags=re.IGNORECASE)\n",
        "\n",
        "# splits a uri into the resource type part (entity, ontology, property, etc) and the resource name part\n",
        "SPLIT_URI_RE = re.compile('https?:\\/\\/dbpedia.org\\/(.*?)\\/(.*)', re.IGNORECASE)\n",
        "\n",
        "# This will capture everything that is between <>, especially useful for LCQUAD\n",
        "FIND_RESOURCES_BTW_ANGLE_BRACKETS_RE = re.compile('\\<(.*?)\\>', re.IGNORECASE)\n",
        "\n",
        "# This will capture everything except what is in resources\n",
        "RE_TEMPLATE_EXCLUDE_SPECIFIC_RESOURCES = '(.*?)({resources}|$)'\n",
        "\n",
        "# this is used to capture parentheses (attr_open and par_close) that follow a filter in interm sparql\n",
        "REPLACE_FILTER_PAR_RE = re.compile(\"(?:FILTER)\\s*?(par_open).*(par_close)\", re.IGNORECASE)\n",
        "\n",
        "# this is used to capture parentheses (attr_open and par_close) that follow a count or an order by in interm sparql\n",
        "REPLACE_REST_PAR_RE = re.compile(\"(?:count|order by (?:asc|desc))\\s*?(par_open).*?(par_close)\", re.IGNORECASE)\n",
        "\n",
        "# this is used to capture quotes that follow a regex in interm sparql to encode them into the 'quote' symbol\n",
        "REPLACE_QUOTES_RE = re.compile(\"regex par_open var_[a-z]+,(').*?(')(?:,(').*?('))? par_close\", re.IGNORECASE)\n",
        "\n",
        "# most math clauses in raw interm sparql have no spaces, so this regex is used to insert some\n",
        "INSERT_SPACES_MATH_RE = re.compile(\"(var_[a-zA-Z0-9]+)(math_[gl]t)(.*?)[$|\\s]\", re.IGNORECASE)\n",
        "\n",
        "# Master regex to catch resources in interm sparql queries in ANY dataset\n",
        "GET_RESOURCES_INTERM_SPARQL_RE = re.compile(\"(db[orcp]_.*?(?:(?:\\s*?(?:attr|par)_open([a-z^db[orcp]_*?)(?:attr|par)_close [a-z^db[orcp]]*?)|(?:\\s*?(?:attr|par)_open(.*?)(?:attr|par)_close)|(?:\\s?_.*?)|(?:,?_.*?)|(?:\\s*?\\-.*?))*\\??)(?:\\s|brack_close)\")\n",
        "\n",
        "# https://stackoverflow.com/a/29922050 - split a resource name that is encoded in camel case into different words\n",
        "CAMEL_CASE_SPLIT_RE = re.compile(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)')\n",
        "\n",
        "# Abbreviations for different types in sparql\n",
        "RESOURCE_ABBRV = 'dbr'\n",
        "PROPERTY_ABBRV  = 'dbp'\n",
        "CLASS_ABBRV = 'dbo'\n",
        "\n",
        "# Names for different types in sparql\n",
        "RESOURCE_TYPE = 'resource'\n",
        "PROPERTY_TYPE = 'property'\n",
        "CLASS_TYPE = 'ontology'\n",
        "\n",
        "\n",
        "# Exceptions to handle when correcting sep dots (useful for DBNQA because lots of formatting errors with sep dots)\n",
        "EXCEPTIONS_NOT_REPLACE = [ 'dbr_Mode._Set._Clear.', 'dbr_Cand.theol.', 'dbr_Observe._Hack._Make.']\n",
        "ENDS_EXCEPTIONS_NOT_REPLACE = ['dept.', 'bros.', 'litt.', 'corp.', 'gent.']\n",
        "ENDS_EXCEPTIONS_REPLACE = ['hop.']\n",
        "\n",
        "# Sparql explicit type for rdf:type, should not be counted as a resource\n",
        "SPARQL_TYPE = \"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"\n",
        "\n",
        "ENDPOINT = \"http://dbpedia.org/sparql\"\n",
        "GRAPH = \"http://dbpedia.org\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUE0GdetHyZB"
      },
      "outputs": [],
      "source": [
        "class Flags:\n",
        "    dbr: bool = False\n",
        "    dbp: bool = False\n",
        "    dbc: bool = False\n",
        "    dbo: bool = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka02sCFy59l8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1jvUNi4Hpgs"
      },
      "outputs": [],
      "source": [
        "def escape_uri_for_regex(uri: str) -> str:\n",
        "    uri = uri.replace('(', '\\(')\n",
        "    uri = uri.replace(')', '\\)')\n",
        "    uri = uri.replace('.', '\\.')\n",
        "    uri = uri.replace('?', '\\?')\n",
        "    uri = uri.replace('*', '\\*')\n",
        "    uri = uri.replace('+', '\\+')\n",
        "    uri = uri.replace(\"'\", \"\\'\")\n",
        "\n",
        "    return uri\n",
        "\n",
        "\n",
        "def convert_to_interm_sparql_except_resources(match: re.Match) -> str:\n",
        "    interm_sparql: str = match.group(0).lower()\n",
        "\n",
        "    for r in PURE_SPARQL_TO_INTERM:\n",
        "        interm_sparql = interm_sparql.replace(\n",
        "            r['pure_sparql'], r['interm_sparql'])\n",
        "\n",
        "    interm_sparql = re.sub('\\s+', ' ', interm_sparql)\n",
        "    return interm_sparql\n",
        "\n",
        "\n",
        "def encode_resources_in_interm_sparql(match: re.Match, keep_uris: bool, flags: Flags = None) -> str:\n",
        "    resource: str = match.group(0)\n",
        "\n",
        "    if flags is not None:\n",
        "        should_replace = flags.dbr and (resource.startswith('<dbr') or resource.startswith('<http://dbpedia.org/resource/'))\n",
        "        should_replace = should_replace or flags.dbp and (resource.startswith('<dbp') or resource.startswith('<http://dbpedia.org/property/'))\n",
        "        should_replace = should_replace or flags.dbc and (resource.startswith('<dbc') or resource.startswith('<http://dbpedia.org/category/'))\n",
        "        should_replace = should_replace or flags.dbo and (resource.startswith('<dbo') or resource.startswith('<http://dbpedia.org/ontology/'))\n",
        "    elif keep_uris and flags is None:\n",
        "        raise ValueError(\"Keep uris is true but no flags provided\")\n",
        "    else:\n",
        "        should_replace = False\n",
        "\n",
        "    for r in URI_SHORTENERS:\n",
        "        if keep_uris and should_replace:\n",
        "            resource = resource.replace(r['match'], r['pure_sparql'])\n",
        "        else:\n",
        "            resource = resource.replace(r['match'], r['interm_sparql'])\n",
        "\n",
        "    if not keep_uris:\n",
        "        for r in PURE_SPARQL_TO_INTERM_RES:\n",
        "            resource = resource.replace(r['pure_sparql'], r['interm_sparql'])\n",
        "\n",
        "    resource = re.sub('\\s+', ' ', resource)\n",
        "\n",
        "    return resource[1:-1]\n",
        "\n",
        "\n",
        "def lowercase_except_resources(match: re.Match) -> str:\n",
        "    sparql: str = match.group(0).lower()\n",
        "    return sparql\n",
        "\n",
        "\n",
        "def encode_resources_in_pure_sparql(match: re.Match) -> str:\n",
        "    resource: str = match.group(0)\n",
        "\n",
        "    for r in URI_SHORTENERS:\n",
        "        resource = resource.replace(r['match'], r['pure_sparql'])\n",
        "\n",
        "    return resource[1:-1]\n",
        "\n",
        "\n",
        "def replace_resource_with_uri(match: re.Match, expressions: List[str], replacement: str) -> str:\n",
        "    to_replace: str = ' ' + match.group(1)\n",
        "    resource: str = match.group(2)\n",
        "\n",
        "    for expr in expressions:\n",
        "        if expr in to_replace:\n",
        "            to_replace = re.sub(f'(\\s{escape_uri_for_regex(expr)})', f' {replacement}', to_replace)\n",
        "            break\n",
        "\n",
        "    return to_replace + resource\n",
        "\n",
        "\n",
        "def correct_parentheses_interm_sparql(match: re.Match) -> str:\n",
        "    dt = {'par_open': 'sparql_open', 'par_close': 'sparql_close'}\n",
        "    whole_match: str = match.group(0)\n",
        "    original_span = match.span(0)\n",
        "    span_open, span_close = match.span(1), match.span(2)\n",
        "\n",
        "    return whole_match[: span_open[0] - original_span[0]] + dt[match.group(1)] + whole_match[span_open[1] - original_span[0] : span_close[0]- original_span[0]] + dt[match.group(2)] + whole_match[span_close[1]- original_span[0]:]\n",
        "\n",
        "\n",
        "def replace_quotes(match: re.Match) -> str:\n",
        "    whole_match = list(match.group(0))\n",
        "    replacement = list(' sparql_quote ')\n",
        "    offset = match.span(0)[0]\n",
        "\n",
        "    for g in range(len(match.groups()), 0, -1):\n",
        "        span = match.span(g)\n",
        "        if span[0] == -1 or span[1] == -1:\n",
        "            continue\n",
        "\n",
        "        whole_match[span[0] - offset : span[1] - offset] = replacement\n",
        "\n",
        "    return ''.join(whole_match)\n",
        "\n",
        "\n",
        "def correct_sep_dots(match: re.Match) -> str:\n",
        "    e = match.group(0).strip()\n",
        "    if e[-1] == '.':\n",
        "        if e in EXCEPTIONS_NOT_REPLACE:\n",
        "            return f' {match.group(0)} '\n",
        "\n",
        "        elif e[-2].isnumeric() or e.split('_')[-1].lower() in ENDS_EXCEPTIONS_REPLACE:\n",
        "            return f' {e[:-1]} sep_dot '\n",
        "\n",
        "        elif len(e.split('.')[-2]) <= 4:\n",
        "            return f' {match.group(0)} '\n",
        "\n",
        "        elif len(e.split('_')[-1]) <= 4 or e.split('_')[-1].lower() in ENDS_EXCEPTIONS_NOT_REPLACE:\n",
        "            return f' {match.group(0)} '\n",
        "        else:\n",
        "            return f' {e[:-1]} sep_dot '\n",
        "\n",
        "    return f' {match.group(0)} '\n",
        "\n",
        "\n",
        "def remove_spaces_from_resources(match: re.Match) -> str:\n",
        "    entity = match.group(0)\n",
        "    entity = entity.replace(' ', '')\n",
        "    entity = entity.replace('\\\\', '')\n",
        "    return f' {entity} '\n",
        "\n",
        "\n",
        "def insert_spaces_math(match: re.Match) -> str:\n",
        "    out = ' '\n",
        "    for m in match.groups():\n",
        "        out += m\n",
        "        out += ' '\n",
        "    return out\n",
        "\n",
        "\n",
        "def insert_resources(m: re.Match, resources: List[str], v:bool = False) -> str:\n",
        "    whole_match = list(m.group(0))\n",
        "    if v:\n",
        "        print(\"WM\", whole_match)\n",
        "\n",
        "    offset = 0\n",
        "\n",
        "    for r in range(len(m.groups())):\n",
        "        replacement_span = m.span(r + 1)\n",
        "        if v:\n",
        "            print(\"group:\", m.groups(r+1))\n",
        "            print(\"repl span:\", replacement_span)\n",
        "            print('replace:', whole_match[replacement_span[0] + offset:replacement_span[1] + offset])\n",
        "            print('by:', resources[r])\n",
        "\n",
        "        whole_match[replacement_span[0] + offset:replacement_span[1] + offset] = list(resources[r])\n",
        "        if v:\n",
        "            print('replaced:', whole_match)\n",
        "\n",
        "        offset += len(resources[r]) - (replacement_span[1] -  replacement_span[0]) # offset  = offset +?\n",
        "\n",
        "        if v:\n",
        "            print('offset:', whole_match)\n",
        "\n",
        "    return ''.join(whole_match)\n",
        "\n",
        "\n",
        "def abstract_resources(match: re.Match) -> str:\n",
        "    NO_REPLACE_PURE = ['dbo:abstract', 'dbp:length', 'dbo:location', 'dbo:designer', 'dbp:complete', 'dbp:nativename', 'dbp:height']\n",
        "    NO_REPLACE_INTERM = ['dbo_abstract', 'dbp_length', 'dbo_location', 'dbo_designer', 'dbp_complete', 'dbp_nativename', 'dbp_height']\n",
        "\n",
        "    if match.group(0).strip().lower() in NO_REPLACE_PURE or match.group(0).strip().lower() in NO_REPLACE_INTERM:\n",
        "        return f' {match.group(0)} '\n",
        "\n",
        "    prefix = match.group(0)[:3]\n",
        "    if prefix not in PLACEHOLDERS:\n",
        "        raise ValueError(f\"UNKNOWN PREFIX: {prefix}\")\n",
        "\n",
        "    return f' {PLACEHOLDERS[prefix]} '\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCD-_TcH6Yyo"
      },
      "source": [
        "### Escape SPARQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIE0etv5Hefu"
      },
      "outputs": [],
      "source": [
        "def correct_interm_sparql(interm_sparql: str) -> str:\n",
        "        should_print = 'attr_open' in interm_sparql\n",
        "        interm_sparql = interm_sparql.replace('attr_open', ' par_open ')\n",
        "        interm_sparql = interm_sparql.replace('attr_close', ' par_close ')\n",
        "\n",
        "        interm_sparql = re.sub('\\s+', ' ', interm_sparql)\n",
        "\n",
        "        interm_sparql = interm_sparql.replace('var_uri.', 'var_uri sep_dot')\n",
        "        interm_sparql = interm_sparql.replace('brack_open', ' brack_open ')\n",
        "        interm_sparql = interm_sparql.replace('brack_close', ' brack_close ')\n",
        "        interm_sparql = interm_sparql.replace('dbp_length', ' dbp_length ')\n",
        "\n",
        "        interm_sparql = REPLACE_FILTER_PAR_RE.sub(\n",
        "            correct_parentheses_interm_sparql, interm_sparql)\n",
        "        interm_sparql = REPLACE_REST_PAR_RE.sub(\n",
        "            correct_parentheses_interm_sparql, interm_sparql)\n",
        "        interm_sparql = REPLACE_QUOTES_RE.sub(replace_quotes, interm_sparql)\n",
        "        interm_sparql = GET_RESOURCES_INTERM_SPARQL_RE.sub(\n",
        "            correct_sep_dots, interm_sparql)\n",
        "        interm_sparql = INSERT_SPACES_MATH_RE.sub(\n",
        "            insert_spaces_math, interm_sparql)\n",
        "\n",
        "        interm_sparql = interm_sparql.replace('FILTER', 'filter')\n",
        "        interm_sparql = interm_sparql.replace('COUNT', 'count')\n",
        "        interm_sparql = interm_sparql.replace('UNION', 'union')\n",
        "\n",
        "        interm_sparql = interm_sparql.replace('%3F', '?')\n",
        "\n",
        "        interm_sparql = re.sub('\\s+', ' ', interm_sparql)\n",
        "        interm_sparql = interm_sparql.strip()\n",
        "\n",
        "        interm_sparql = interm_sparql.replace('par_open', 'attr_open')\n",
        "        interm_sparql = interm_sparql.replace('par_close', 'attr_close')\n",
        "        interm_sparql = interm_sparql.replace('sparql_open', 'par_open')\n",
        "        interm_sparql = interm_sparql.replace('sparql_close', 'par_close')\n",
        "\n",
        "        return interm_sparql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z08CgrlkA2S-"
      },
      "outputs": [],
      "source": [
        "def reverse_replacements(query: str) -> str:\n",
        "    for r in REPLACEMENTS:\n",
        "        original = r[0]\n",
        "        encoding = r[-1]\n",
        "        query = query.replace(encoding, original)\n",
        "        stripped_encoding = str.strip(encoding)\n",
        "        query = query.replace(stripped_encoding, original)\n",
        "\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_order_by(query: str) -> str:\n",
        "    matches = REPLACE_ORDER_BY_RE.findall(query)\n",
        "\n",
        "    if len(matches) == 0:\n",
        "        return query\n",
        "\n",
        "    matches = matches[0]\n",
        "\n",
        "    if len(matches) > 3:\n",
        "        raise ValueError(f\"The query '{query}' has more than one order by!\")\n",
        "\n",
        "    if matches[1] == \"_oba_\":\n",
        "        order_by = \"ORDER BY ASC(\"\n",
        "    elif matches[1] == \"_obd_\":\n",
        "        order_by = \"ORDER BY DESC(\"\n",
        "\n",
        "    order_by_str = order_by + matches[2] + \")\"\n",
        "    query = query.replace(matches[0], order_by_str)\n",
        "\n",
        "    return query\n",
        "\n",
        "\n",
        "def remove_spaces_from_resources(match: re.Match) -> str:\n",
        "    entity = match.group(0)\n",
        "    entity = entity.replace(\" \", \"\")\n",
        "    entity = entity.replace(\"\\\\\", \"\")\n",
        "    entity = entity.replace(' attr_dot ', \".\")\n",
        "    entity = entity.replace(' attr_dot', \".\")\n",
        "    entity = entity.replace('attr_dot ', \".\")\n",
        "    entity = entity.replace('attr_dot', \".\")\n",
        "    return f\" {entity} \"\n",
        "\n",
        "\n",
        "def add_var_in_resource_names(match: re.Match) -> str:\n",
        "    return str(match.group(0).replace('?', 'var_'))\n",
        "\n",
        "\n",
        "def interm_sparql_to_pure_sparql(interm_query: str):\n",
        "    interm_query = correct_interm_sparql(interm_query)\n",
        "    query = reverse_replacements(interm_query)\n",
        "    query = escape_order_by(query)\n",
        "    query = CATCH_VAR_IN_RESOURCE_NAME_RE.sub(add_var_in_resource_names, query)\n",
        "    query = query.replace(\"where{\", \"where {\")\n",
        "    query = query.replace(\"}\", \" } \")\n",
        "    query = query.replace(\"FILTER\", \"filter\")\n",
        "    query = query.replace(\"COUNT\", \"count\")\n",
        "    query = query.replace(\"UNION\", \"union\")\n",
        "\n",
        "    query = GET_RESOURCES_PURE_SPARQL_RE.sub(remove_spaces_from_resources, query)\n",
        "\n",
        "    query = query.replace(\"dbp:length\", \" dbp:length \")\n",
        "    query = re.sub(\" ?%3F\", \"?\", query)\n",
        "    query = re.sub(\"\\s+\", \" \", query)\n",
        "    query = query.strip()\n",
        "    return query\n",
        "\n",
        "\n",
        "def generate_pure_sparql(interm_sparql: List[str]) -> List[str]:\n",
        "    pure_sparql = []\n",
        "\n",
        "    for interm_query in interm_sparql:\n",
        "        query = interm_sparql_to_pure_sparql(interm_query)\n",
        "        pure_sparql.append(query)\n",
        "    \n",
        "    return pure_sparql\n",
        "\n",
        "\n",
        "def escape_parentheses_in_entities(match: re.Match) -> str:\n",
        "    resource: str = match.group(0)\n",
        "    resource = resource.replace('(', '\\\\(')\n",
        "    resource = resource.replace(')', '\\\\)')\n",
        "    return resource\n",
        "\n",
        "\n",
        "def escape_parentheses(query: str) -> str:\n",
        "    query = GET_RESOURCES_PURE_SPARQL_RE.sub(escape_parentheses_in_entities, query)\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_ampersands(query: str) -> str:\n",
        "    amp = query.find('&')\n",
        "    while amp > 0:\n",
        "        if query[amp - 1] != '&' and query[amp + 1] != '&':\n",
        "            query = query[:amp] + '\\\\' + query[amp:]\n",
        "        amp = query.find('&', amp + 2)\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_dots_in_resources(match:re.Match) -> str:\n",
        "    full_match: str = match.group(0)\n",
        "    return full_match.replace('.', '\\\\.')\n",
        "\n",
        "\n",
        "def escape_dots(query: str) -> str:\n",
        "    query = GET_RESOURCES_PURE_SPARQL_RE.sub(escape_dots_in_resources, query)\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_plus(query: str) -> str:\n",
        "    idx = query.find('+')\n",
        "    while idx > 0:\n",
        "        query = query[:idx] + '\\\\' + query[idx:]\n",
        "        idx = query.find('+', idx + 2)\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_star(query: str) -> str:\n",
        "    idx = query.find('*')\n",
        "    while idx > 0:\n",
        "        query = query[:idx] + '\\\\' + query[idx:]\n",
        "        idx = query.find('*', idx + 2)\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_query(query: str) -> str:\n",
        "    query = escape_parentheses(query)\n",
        "    query = escape_ampersands(query)\n",
        "    query = escape_dots(query)\n",
        "    query = escape_plus(query)\n",
        "    # query = escape_star(query)\n",
        "    query = escape_order_by(query)\n",
        "    query = query.replace(\"'\", \"\\\\'\")\n",
        "    query = query.replace(\",\", \"\\\\,\")\n",
        "    query = query.replace(\"!\", \"\\\\!\")\n",
        "    query = query.replace(\"/\", \"\\\\/\")\n",
        "    return query\n",
        "\n",
        "\n",
        "def escape_for_querying(pure_sparql: List[str]) -> List[str]:\n",
        "    escaped_sparql = []\n",
        "    for query in tqdm(pure_sparql):\n",
        "        escaped_sparql.append(escape_query(query))\n",
        "    return escaped_sparql\n",
        "\n",
        "\n",
        "def convert_to_pure_sparql(in_path_intem_sparql: str, out_path_pure_sparql: str, escape: bool = False) -> None:\n",
        "    interm_sparql = open(in_path_intem_sparql, 'r',\n",
        "                         encoding=\"utf-8\").read().strip().split('\\n')\n",
        "\n",
        "    pure_sparql = generate_pure_sparql(interm_sparql)\n",
        "\n",
        "    if escape:\n",
        "        pure_sparql = escape_for_querying(pure_sparql)\n",
        "\n",
        "    with open(out_path_pure_sparql, 'w', encoding=\"utf-8\") as f:\n",
        "        f.writelines('\\n'.join(pure_sparql))\n",
        "\n",
        "\n",
        "def generate_pure_sparql(interm_sparql: str, to_pr = False) -> str:\n",
        "    pure_sparql: str = interm_sparql_to_pure_sparql(interm_sparql)\n",
        "    # if to_pr:\n",
        "      # print('HI', pure_sparql)\n",
        "    pure_sparql = escape_query(pure_sparql)\n",
        "    pure_sparql = pure_sparql.replace(' var_b ', ' ?b ')\n",
        "    pure_sparql = pure_sparql.replace('<', '')\n",
        "    return pure_sparql.replace('>', '')\n",
        "\n",
        "\n",
        "def generate_pure_sparql_for_report(partial_report: List[Dict[str, str]]) -> List[Dict[str, str]]:\n",
        "    for id in range(len(partial_report)):\n",
        "        partial_report[id]['pure_trg'] = generate_pure_sparql(partial_report[id]['trg'], partial_report[id]['id'] == '4016')\n",
        "        partial_report[id]['pure_predicted']= generate_pure_sparql(partial_report[id]['predicted'])\n",
        "\n",
        "    return partial_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJa1IjkT7JN9"
      },
      "source": [
        "### Query DBpedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t56DTBZS7LCE"
      },
      "outputs": [],
      "source": [
        "def query_dbpedia(query: str) -> Dict[Any, Any]:\n",
        "    sparql = SPARQLWrapper(ENDPOINT)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "\n",
        "    sparql.setQuery(query)\n",
        "\n",
        "    response: Dict[Any, Any] = sparql.query().convert()\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK1kPDxO8iy1"
      },
      "outputs": [],
      "source": [
        "def query_dbpedia_for_report(complete_report: List[Dict[str, str]], predicted=False) -> List[Dict[str, str]]:\n",
        "    dbpedia_key = 'predicted' if predicted else 'trg'\n",
        "    pure_sparql_key = 'pure_predicted' if predicted else 'pure_trg'\n",
        "\n",
        "    for entry in tqdm(complete_report):\n",
        "        try:\n",
        "            dbpedia_data = entry.get('dbpedia', {'predicted': {}, 'trg': {}})\n",
        "            dbpedia_data[dbpedia_key]['query_result'] = query_dbpedia(entry[pure_sparql_key])\n",
        "            dbpedia_data[dbpedia_key]['is_error'] = False\n",
        "            entry['dbpedia'] = dbpedia_data\n",
        "\n",
        "        except Exception as error:\n",
        "            print(f\"[ERROR] at query id {entry['id']}:\")\n",
        "            print(error)\n",
        "            dbpedia_data = entry.get('dbpedia', {'predicted': {}, 'trg': {}})\n",
        "            dbpedia_data[dbpedia_key]['query_result'] = []\n",
        "            dbpedia_data[dbpedia_key]['is_error'] = True\n",
        "            entry['dbpedia'] = dbpedia_data\n",
        "\n",
        "    return complete_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYMZuz0U8L-D"
      },
      "source": [
        "### Get Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlYtV_MC8pso"
      },
      "outputs": [],
      "source": [
        "def get_full_report_metrics(report: List[Dict]):\n",
        "    report_metrics = {}\n",
        "    # bleu score\n",
        "    predicted = [entry['predicted'].replace(':', '_').split() for entry in report]\n",
        "    trg = [[entry['trg'].replace(':', '_').split()] for entry in report]\n",
        "\n",
        "    report_metrics['bleu_score'] = f\"{bleu_score(predicted, trg)}\"\n",
        "\n",
        "    # answer accuracy\n",
        "    if 'dbpedia' in report[0]:\n",
        "        answers = [(entry['dbpedia']['predicted'], entry['dbpedia']['trg']) for entry in report]\n",
        "        error_predicted_count = 0\n",
        "        error_ground_truth_count = 0\n",
        "        correct_answer_count = 0\n",
        "        count_empty = 0\n",
        "\n",
        "        for a in answers:\n",
        "            if a[0] == a[1]:\n",
        "              correct_answer_count += 1\n",
        "            \n",
        "        report_metrics['answer_accuracy'] = f\"{correct_answer_count/len(report)}\"\n",
        "        \n",
        "    else:\n",
        "        print(\"No info available on answer accuracy\")\n",
        "\n",
        "    return report_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlkYuVVqQ1hv"
      },
      "outputs": [],
      "source": [
        "def get_precision_recall(report: List[Dict]):\n",
        "  report_metrics = {}\n",
        "  \n",
        "  tn_cnt = 0\n",
        "  tp_cnt = 0\n",
        "  fn_cnt = 0\n",
        "  fp_cnt = 0\n",
        "  \n",
        "  if 'dbpedia' in report[0]:\n",
        "    answers = [(entry['dbpedia']['predicted'], entry['dbpedia']['trg']) for entry in report]\n",
        "\n",
        "    # suivant: https://github.com/semantic-systems/NLIWOD\n",
        "    # ex: https://github.com/semantic-systems/NLIWOD/blob/8871cd937420350be135e6542a6f3f6a0cc1cc4c/qa.ml/src/main/java/org/aksw/mlqa/utils/PrintCSV.java\n",
        "    # TN: pred vide et gold vide\n",
        "    # FN: pred vide et gold pas vide\n",
        "    # TP: pred pas vide == gold pas vide\n",
        "    # FP: pred pas vide et gold vide OU pred pas vide != gold pas vide\n",
        "\n",
        "\n",
        "    for a in answers:\n",
        "      try:\n",
        "        predIsError = a[0]['is_error']\n",
        "        goldIsError = a[1]['is_error']\n",
        "\n",
        "        predIsBoolean = not predIsError and 'boolean' in a[0]['query_result']\n",
        "        goldIsBoolean = not goldIsError and 'boolean' in a[1]['query_result']\n",
        "\n",
        "        predBooleanValue = predIsBoolean and a[0]['query_result']['boolean']\n",
        "        goldBooleanValue = predIsBoolean and a[1]['query_result']['boolean']\n",
        "\n",
        "        predIsEmptyList = not predIsError and not predIsBoolean and len(a[0]['query_result']['results']['bindings']) == 0\n",
        "        goldIsEmptyList = not goldIsError and not goldIsBoolean and len(a[1]['query_result']['results']['bindings']) == 0\n",
        "\n",
        "        predIsEmptyCount = not predIsError and not predIsBoolean and not predIsEmptyList and 'value' in a[0]['query_result']['results']['bindings'][0] and a[0]['query_result']['results']['bindings'][0]['value'] == 0\n",
        "        goldIsEmptyCount = not predIsError and not goldIsBoolean and not goldIsEmptyList and 'value' in a[1]['query_result']['results']['bindings'][0] and a[1]['query_result']['results']['bindings'][0]['value'] == 0\n",
        "\n",
        "        predIsEmpty = predIsError or (predIsBoolean and not predBooleanValue) or predIsEmptyCount or predIsEmptyList\n",
        "        goldIsEmpty = goldIsError or (goldIsBoolean and not goldBooleanValue) or goldIsEmptyCount or goldIsEmptyList\n",
        "\n",
        "        for a in answers:\n",
        "            if predIsEmpty and goldIsEmpty:\n",
        "              tn_cnt += 1\n",
        "\n",
        "            elif predIsEmpty and not goldIsEmpty:\n",
        "              fn_cnt += 1\n",
        "            \n",
        "            elif (not predIsEmpty and goldIsEmpty) or a[0] != a[1]:\n",
        "              fp_cnt += 1\n",
        "            \n",
        "            elif a[0] == a[1]:\n",
        "              tp_cnt += 1\n",
        "\n",
        "            else:\n",
        "              print(\"WHAT HAPPENED HERE\")\n",
        "\n",
        "      except Exception as e: \n",
        "        print(\"ERROR\")\n",
        "        print(e)\n",
        "        print(a[0])\n",
        "        print(a[1])\n",
        "\n",
        "\n",
        "    report_metrics['recall'] = tp_cnt/(tp_cnt+fn_cnt)\n",
        "    report_metrics['precision'] = tp_cnt/(tp_cnt+fp_cnt)\n",
        "  \n",
        "  return report_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuChkqhq8PQd"
      },
      "outputs": [],
      "source": [
        "def generate_report(error_report_path: str, run_template_metrics: bool, run_dbpedia: bool, out) -> List[Dict]:\n",
        "    with open(error_report_path, 'r', encoding='utf-8') as f:\n",
        "        report = json.load(f)\n",
        "\n",
        "    complete_report = generate_pure_sparql_for_report(report)\n",
        "\n",
        "\n",
        "    if run_dbpedia:\n",
        "        print(\"QUERYING DBPEDIA FOR EXPECTED RESULT...\")\n",
        "        complete_report = query_dbpedia_for_report(complete_report, predicted=False)\n",
        "        print(\"QUERYING DBPEDIA FOR PREDICTED RESULT...\")\n",
        "        complete_report = query_dbpedia_for_report(complete_report, predicted=True)\n",
        "\n",
        "    with open(out, 'w') as f:\n",
        "      json.dump(complete_report, f)\n",
        "\n",
        "    #full_report_metrics = get_full_report_metrics(complete_report)\n",
        "    full_report_metrics = get_precision_recall(complete_report)\n",
        "\n",
        "    print('FULL REPORT:')\n",
        "    for key, val in full_report_metrics.items():\n",
        "        print(f'\\t{key}: {val}')\n",
        "\n",
        "    return full_report_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gip_AQZz7gRl"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKp91Ivn7kOj",
        "outputId": "7f62e2bd-2ee4-4b83-b2db-fdad40909562"
      },
      "outputs": [],
      "source": [
        "models_paths = glob.glob(f\"{MODELS_FOLDER}/*\")\n",
        "reports_paths = [f'{m}/{REPORT_FILENAME}' for m in models_paths]\n",
        "print(reports_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPtE79ob9s67",
        "outputId": "b97ac9f0-1678-4d28-f7a2-618309abccb3"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for i, r in enumerate(reports_paths):\n",
        "  print(r)\n",
        "  out = MODELS_FOLDER + str(i+1) + '/error_report_complete.json'\n",
        "  res = generate_report(r, False, True, out)\n",
        "  print(res)\n",
        "  results.append(res)\n",
        "  print('-----------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMtXlkhQAATr"
      },
      "outputs": [],
      "source": [
        "print(reports_paths[0])\n",
        "print(\"PRECISION AVERAGE:\", sum([float(r['precision']) for r in results]) / len(results))\n",
        "print(\"RECALL AVERAGE:\", sum([float(r['recall']) for r in results]) / len(results))\n",
        "print(\"F1 AVERAGE:\", sum([2*(r['precision']*r['recall'])/(r['precision'] + r['recall']) for r in results])/len(results))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "K9YuxEjjwj5Z",
        "sCD-_TcH6Yyo",
        "hYMZuz0U8L-D"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
