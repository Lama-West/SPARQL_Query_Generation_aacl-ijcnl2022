{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT_50aM95Hku"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Any, Tuple, Union\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import files, drive\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvLRklGs8BZY",
        "outputId": "fe16e3e9-6965-4747-8699-8019197ff384"
      },
      "outputs": [],
      "source": [
        "# connect to google drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv1bgxw1zkfC"
      },
      "outputs": [],
      "source": [
        "MODEL_TYPE = [\"transformer\", \"cnns2s\"] # cnns2s or transformer\n",
        "COPY_FLAG = [\"no_copy\", \"copy\"] # or no_copy\n",
        "DATASET_FAMILY = \"LC-QuAD\" # Monument or LC-QuAD\n",
        "DATASET_NAME = \"intermediary_question_tagged_all_no_resources\" # DONT FORGET TO SET\n",
        "REPORT_FILENAME = 'error_report_complete.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka02sCFy59l8"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBvbhXFks2CA"
      },
      "outputs": [],
      "source": [
        "def load_report(path: str):\n",
        "  try:\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "      answer_report = json.load(f)\n",
        "    print(len(answer_report))\n",
        "\n",
        "    if ('oov' not in path and len(answer_report) == 250):\n",
        "      print(f\"1 - MUST RERUN {path}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"2 - MUST RERUN {path}: {e}\")\n",
        "    answer_report = []\n",
        "\n",
        "  return answer_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jKaaVlz1Ibj"
      },
      "outputs": [],
      "source": [
        "def get_answers(path):\n",
        "  report = load_report(path)\n",
        "  answers = []\n",
        "\n",
        "  if len(report) > 0 and 'dbpedia' in report[0]:\n",
        "    raw_answers = [(entry['dbpedia']['predicted'], entry['dbpedia']['trg']) for entry in report]\n",
        "  \n",
        "  else:\n",
        "    print(f\"3 - MUST RERUN {path}\")\n",
        "    return []\n",
        "\n",
        "  for a in raw_answers:\n",
        "\n",
        "    gold = []\n",
        "    pred = []\n",
        "\n",
        "    predIsError = a[0]['is_error']\n",
        "    goldIsError = a[1]['is_error']\n",
        "\n",
        "    if predIsError or goldIsError:\n",
        "      answers.append(([], []))\n",
        "      continue\n",
        " \n",
        "    predIsBoolean = not predIsError and 'boolean' in a[0]['query_result']\n",
        "    goldIsBoolean = not goldIsError and 'boolean' in a[1]['query_result']\n",
        "\n",
        "    if predIsBoolean:\n",
        "      pred = [a[0]['query_result']['boolean']]\n",
        "    \n",
        "\n",
        "    if goldIsBoolean:\n",
        "      gold = [a[1]['query_result']['boolean']]\n",
        "    \n",
        "\n",
        "    predIsEmptyList = not predIsError and not predIsBoolean and len(a[0]['query_result']['results']['bindings']) == 0\n",
        "    goldIsEmptyList = not goldIsError and not goldIsBoolean and len(a[1]['query_result']['results']['bindings']) == 0\n",
        "\n",
        "    if predIsEmptyList or goldIsEmptyList:\n",
        "      answers.append(([], []))\n",
        "      continue\n",
        "\n",
        "    predIsCount = not predIsBoolean and 'value' in a[0]['query_result']['results']['bindings'][0]\n",
        "    goldIsCount = not goldIsBoolean and 'value' in a[1]['query_result']['results']['bindings'][0]\n",
        "\n",
        "    if predIsCount:\n",
        "      pred = [a[0]['query_result']['results']['bindings'][0]['value']]\n",
        "\n",
        "    if goldIsCount:\n",
        "      gold = [a[1]['query_result']['results']['bindings'][0]['value']]\n",
        "\n",
        "    \n",
        "    if not predIsCount and not predIsBoolean:\n",
        "      pred = a[0]['query_result']['results']['bindings']\n",
        "    \n",
        "    if not goldIsCount and not goldIsBoolean:\n",
        "      gold = a[1]['query_result']['results']['bindings']\n",
        "\n",
        "\n",
        "    answers.append((pred, gold))\n",
        "\n",
        "  return answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtYSegZM4OU2"
      },
      "outputs": [],
      "source": [
        "def get_prec_and_recall(path):\n",
        "  answers = get_answers(path)\n",
        "\n",
        "  if len(answers) == 0 :\n",
        "    return 0,0\n",
        "\n",
        "  prec = []\n",
        "  recall = []\n",
        "\n",
        "  for pred, gold in answers:\n",
        "    if len(pred) == 0 or len(gold) == 0:\n",
        "      prec.append(0)\n",
        "      recall.append(0)\n",
        "      continue\n",
        "\n",
        "    count = 0\n",
        "    for correct in gold:\n",
        "      for found in pred:\n",
        "        if correct == found:\n",
        "          count += 1\n",
        "          break\n",
        "\n",
        "    recall.append(count / len(gold))\n",
        "    prec.append(count / len(pred))\n",
        "    \n",
        "  out_prec = sum(prec) / len(prec)\n",
        "  out_recall = sum(recall) / len(recall)\n",
        "\n",
        "  return out_prec, out_recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3i62Ufy6Etj"
      },
      "outputs": [],
      "source": [
        "def get_f1(prec, recall):\n",
        "  if prec == 0 or recall == 0:\n",
        "    return 0\n",
        "\n",
        "  else:\n",
        "    return 2*(prec*recall) / (prec + recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gip_AQZz7gRl"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKp91Ivn7kOj",
        "outputId": "85000ad6-e60b-41a9-d79f-796124e277fb"
      },
      "outputs": [],
      "source": [
        "for c in COPY_FLAG:\n",
        "  for m in MODEL_TYPE:\n",
        "    print('===============================================')\n",
        "    MODELS_FOLDER = f\"/content/gdrive/MyDrive/PRETRAINED/{m}/{c}/{DATASET_FAMILY}/{DATASET_NAME}/\"\n",
        "\n",
        "    models_paths = glob.glob(f\"{MODELS_FOLDER}/*\")\n",
        "    reports_paths = [f'{m}/{REPORT_FILENAME}' for m in models_paths]\n",
        "    print(MODELS_FOLDER, len(reports_paths))\n",
        "\n",
        "    results = []\n",
        "    for r in reports_paths:\n",
        "      print(r)\n",
        "      prec, recall = get_prec_and_recall(r)\n",
        "      f1 = get_f1(prec, recall)\n",
        "\n",
        "      results.append((prec, recall, f1))\n",
        "\n",
        "    if len(results) == 3:\n",
        "      print(\"PRECISION AVERAGE:\", sum([r[0] for r in results]) / len(results) * 100)\n",
        "      print(\"RECALL AVERAGE:\", sum([r[1] for r in results]) / len(results) * 100)\n",
        "      print(\"F1 AVERAGE:\", sum([r[2] for r in results])/len(results) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcHsGtRxICmb"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
